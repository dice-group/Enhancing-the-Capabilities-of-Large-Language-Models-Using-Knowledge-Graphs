{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~umpy (c:\\Users\\z0050t3j\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~umpy (c:\\Users\\z0050t3j\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~umpy (c:\\Users\\z0050t3j\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages)\n",
      "\n",
      "[notice] A new release of pip is available: 25.0 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: faker in c:\\users\\z0050t3j\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (36.1.0)\n",
      "Requirement already satisfied: tzdata in c:\\users\\z0050t3j\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from faker) (2024.2)\n"
     ]
    }
   ],
   "source": [
    "%pip install faker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "import hashlib\n",
    "from faker import Faker\n",
    "from rdflib import Graph, Literal, URIRef, Namespace\n",
    "from rdflib.namespace import RDF\n",
    "from azure.identity import DefaultAzureCredential\n",
    "from azure.keyvault.secrets import SecretClient\n",
    "from openai import AzureOpenAI\n",
    "from types import SimpleNamespace\n",
    "\n",
    "# Namespaces\n",
    "SCHEMA = Namespace(\"https://schema.org/\")\n",
    "APP = Namespace(\"http://application.com/\")\n",
    "PRO = Namespace(\"http://process.com/\")\n",
    "ORG1 = Namespace(\"http://organization.com/\")\n",
    "EMP = Namespace(\"http://employee.com/\")\n",
    "FIN = Namespace(\"http://financial.com/\")\n",
    "\n",
    "# Load configuration\n",
    "def load_config():\n",
    "    try:\n",
    "        with open(r\"config.json\") as f:\n",
    "            config = json.load(f, object_hook=lambda d: SimpleNamespace(**d))\n",
    "        print(\"Config loaded:\", vars(config))\n",
    "        return config\n",
    "    except FileNotFoundError:\n",
    "        raise FileNotFoundError(\"Config file not found. Please check the path.\")\n",
    "\n",
    "# Initialize Azure OpenAI client\n",
    "def initialize_azure_client(config):\n",
    "    client = SecretClient(vault_url=config.key_vault_url, credential=DefaultAzureCredential())\n",
    "    secret = client.get_secret(config.dev_secret_name)\n",
    "    llm = AzureOpenAI(\n",
    "        api_key=secret.value,\n",
    "        api_version=config.chat.api_version,\n",
    "        azure_endpoint=config.chat.azure_endpoint\n",
    "    )\n",
    "    print(\"AzureOpenAI client initialized\")\n",
    "    return llm\n",
    "\n",
    "# LLM-based text generation\n",
    "def generate_with_llm(llm, config, entity_type, field_name, old_value):\n",
    "    prompt = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": f\"\"\"\n",
    "            You are an AI assistant tasked with generating anonymized values for a financial department's software industry knowledge graph.\n",
    "            Generate a realistic and contextually appropriate replacement for the given {entity_type} {field_name}.\n",
    "            - Ensure the output aligns with a financial/software context (e.g., company names, job titles, process titles, or app names).\n",
    "            - Avoid using the original value: '{old_value}'.\n",
    "            - If the original value contains codes, abbreviations, or separators (e.g., '-', 'SE', 'FIN'), create a plausible name that mimics corporate or technical naming conventions.\n",
    "            - Keep the length and tone similar to the original where possible.\n",
    "\n",
    "            Original {field_name}: '{old_value}'\n",
    "            Provide a single anonymized value as output.\n",
    "            \"\"\"\n",
    "        }\n",
    "    ]\n",
    "    try:\n",
    "        response = llm.chat.completions.create(\n",
    "            model=config.chat.model,\n",
    "            messages=prompt\n",
    "        )\n",
    "        content = response.choices[0].message.content\n",
    "        if content is None:\n",
    "            print(f\"Warning: LLM returned None for {entity_type} {field_name} with old_value '{old_value}'\")\n",
    "            fake = deterministic_faker(str(old_value))\n",
    "            if entity_type == \"Organization\" and field_name == \"name\":\n",
    "                return fake.company()\n",
    "            elif entity_type == \"Organization\" and field_name == \"description\":\n",
    "                return fake.catch_phrase()\n",
    "            elif entity_type == \"Person\" and field_name == \"jobTitle\":\n",
    "                return fake.job()\n",
    "            elif entity_type == \"Application\" and field_name == \"appName\":\n",
    "                return fake.word().title() + \"App\"\n",
    "            elif entity_type == \"Application\" and field_name == \"appDescription\":\n",
    "                return fake.sentence(nb_words=8)\n",
    "            elif entity_type == \"Process\" and field_name == \"title\":\n",
    "                return \"Process \" + fake.word().title()\n",
    "            elif entity_type == \"Process\" and field_name == \"description\":\n",
    "                return fake.sentence(nb_words=10)\n",
    "            return \"Anonymized Placeholder\"\n",
    "        return content.strip()\n",
    "    except Exception as e:\n",
    "        print(f\"Error in generate_with_llm: {e}, old_value: '{old_value}'\")\n",
    "        raise\n",
    "\n",
    "# Deterministic Faker\n",
    "def deterministic_faker(seed_str, locale=\"en_US\"):\n",
    "    fake = Faker(locale)\n",
    "    hash_int = int(hashlib.sha256(seed_str.encode('utf-8')).hexdigest(), 16) % (10**8)\n",
    "    fake.seed_instance(hash_int)\n",
    "    return fake\n",
    "\n",
    "# Anonymization Functions\n",
    "def anonymize_person(graph, person, llm, config):\n",
    "    mapping_record = {}\n",
    "    gid = str(graph.value(person, SCHEMA.gid) or person)\n",
    "    fake = deterministic_faker(gid)\n",
    "    \n",
    "    old_given = str(graph.value(person, SCHEMA.givenName) or \"\")\n",
    "    old_family = str(graph.value(person, SCHEMA.familyName) or \"\")\n",
    "    old_email = str(graph.value(person, SCHEMA.email) or \"\")\n",
    "    old_job = str(graph.value(person, SCHEMA.jobTitle) or \"\")\n",
    "    old_tel = str(graph.value(person, SCHEMA.telephone) or \"\")\n",
    "    old_location = str(graph.value(person, SCHEMA.location) or \"\")\n",
    "    old_id = str(graph.value(person, SCHEMA.id) or \"\")\n",
    "    \n",
    "    given_parts = old_given.split()\n",
    "    new_given = \" \".join([fake.first_name() for _ in given_parts]) if given_parts else fake.first_name()\n",
    "    new_family = fake.last_name()\n",
    "    new_email = f\"{new_given.lower().replace(' ', '.')}.{new_family.lower()}@example.net\"\n",
    "    new_job = generate_with_llm(llm, config, \"Person\", \"jobTitle\", old_job) if old_job else fake.job()\n",
    "    new_tel = fake.phone_number()\n",
    "    new_location = fake.city()\n",
    "    new_gid = fake.bothify(text=\"Z########\")\n",
    "    person_str = str(person)\n",
    "    new_id = person_str.split(\"emp:\")[-1] if \"emp:\" in person_str else old_id\n",
    "    \n",
    "    graph.set((person, SCHEMA.givenName, Literal(new_given)))\n",
    "    graph.set((person, SCHEMA.familyName, Literal(new_family)))\n",
    "    graph.set((person, SCHEMA.email, Literal(new_email)))\n",
    "    graph.set((person, SCHEMA.jobTitle, Literal(new_job)))\n",
    "    graph.set((person, SCHEMA.telephone, Literal(new_tel)))\n",
    "    graph.set((person, SCHEMA.location, Literal(new_location)))\n",
    "    graph.set((person, SCHEMA.gid, Literal(new_gid)))\n",
    "    graph.set((person, SCHEMA.id, Literal(new_id)))\n",
    "    \n",
    "    mapping_record.update({\n",
    "        \"givenName\": {\"old\": old_given, \"new\": new_given},\n",
    "        \"familyName\": {\"old\": old_family, \"new\": new_family},\n",
    "        \"email\": {\"old\": old_email, \"new\": new_email},\n",
    "        \"jobTitle\": {\"old\": old_job, \"new\": new_job},\n",
    "        \"telephone\": {\"old\": old_tel, \"new\": new_tel},\n",
    "        \"location\": {\"old\": old_location, \"new\": new_location},\n",
    "        \"gid\": {\"old\": gid, \"new\": new_gid},\n",
    "        \"id\": {\"old\": old_id, \"new\": new_id}\n",
    "    })\n",
    "    return mapping_record\n",
    "\n",
    "def anonymize_organization(graph, org, llm, config):\n",
    "    mapping_record = {}\n",
    "    org_str = str(org)\n",
    "    new_orgId = org_str.split(\"org1:\")[-1] if \"org1:\" in org_str else str(graph.value(org, SCHEMA.orgId) or \"\")\n",
    "    fake = deterministic_faker(new_orgId)\n",
    "    \n",
    "    old_name = str(graph.value(org, SCHEMA.name) or \"\")\n",
    "    old_description = str(graph.value(org, SCHEMA.description) or \"\")\n",
    "    old_orgID = str(graph.value(org, SCHEMA.orgID) or \"\")\n",
    "    old_real_orgId = str(graph.value(org, SCHEMA.orgId) or \"\")\n",
    "    \n",
    "    new_name = generate_with_llm(llm, config, \"Organization\", \"name\", old_name) if old_name else fake.company()\n",
    "    new_description = generate_with_llm(llm, config, \"Organization\", \"description\", old_description) if old_description else fake.catch_phrase()\n",
    "    \n",
    "    graph.remove((org, SCHEMA.orgID, None))\n",
    "    graph.set((org, SCHEMA.name, Literal(new_name)))\n",
    "    graph.set((org, SCHEMA.description, Literal(new_description)))\n",
    "    graph.set((org, SCHEMA.orgId, Literal(new_orgId)))\n",
    "    \n",
    "    mapping_record.update({\n",
    "        \"name\": {\"old\": old_name, \"new\": new_name},\n",
    "        \"orgID_removed\": old_orgID,\n",
    "        \"orgId\": {\"old\": old_real_orgId, \"new\": new_orgId},\n",
    "        \"description\": {\"old\": old_description, \"new\": new_description}\n",
    "    })\n",
    "    return mapping_record\n",
    "\n",
    "def anonymize_application(graph, app, llm, config):\n",
    "    mapping_record = {}\n",
    "    app_str = str(app)\n",
    "    new_appId = app_str.split(\"app:\")[-1] if \"app:\" in app_str else str(graph.value(app, APP.appId) or \"\")\n",
    "    fake = deterministic_faker(new_appId)\n",
    "    \n",
    "    old_name = str(graph.value(app, APP.appName) or \"\")\n",
    "    old_description = str(graph.value(app, APP.appDescription) or \"\")\n",
    "    old_appId = str(graph.value(app, APP.appId) or \"\")\n",
    "    old_accessLink = str(graph.value(app, APP.accessLink) or \"\")\n",
    "    old_appLink = str(graph.value(app, APP.appLink) or \"\")\n",
    "    old_appImage = str(graph.value(app, APP.appImage) or \"\")\n",
    "    \n",
    "    new_name = generate_with_llm(llm, config, \"Application\", \"appName\", old_name) if old_name else fake.word().title() + \"App\"\n",
    "    new_description = generate_with_llm(llm, config, \"Application\", \"appDescription\", old_description) if old_description else fake.sentence(nb_words=8)\n",
    "    new_accessLink = fake.url()\n",
    "    new_appLink = fake.url()\n",
    "    \n",
    "    graph.set((app, APP.appName, Literal(new_name)))\n",
    "    graph.set((app, APP.appDescription, Literal(new_description)))\n",
    "    graph.set((app, APP.appId, Literal(new_appId)))\n",
    "    graph.set((app, APP.accessLink, Literal(new_accessLink)))\n",
    "    graph.set((app, APP.appLink, Literal(new_appLink)))\n",
    "    graph.remove((app, APP.appImage, None))\n",
    "    \n",
    "    mapping_record.update({\n",
    "        \"appName\": {\"old\": old_name, \"new\": new_name},\n",
    "        \"appDescription\": {\"old\": old_description, \"new\": new_description},\n",
    "        \"appId\": {\"old\": old_appId, \"new\": new_appId},\n",
    "        \"accessLink\": {\"old\": old_accessLink, \"new\": new_accessLink},\n",
    "        \"appLink\": {\"old\": old_appLink, \"new\": new_appLink},\n",
    "        \"appImage\": {\"old\": old_appImage, \"new\": None}\n",
    "    })\n",
    "    return mapping_record\n",
    "\n",
    "def anonymize_process(graph, proc, llm, config):\n",
    "    mapping_record = {}\n",
    "    proc_str = str(proc)\n",
    "    new_processId = proc_str.split(\"pro:\")[-1] if \"pro:\" in proc_str else str(graph.value(proc, PRO.processId) or \"\")\n",
    "    fake = deterministic_faker(new_processId)\n",
    "    \n",
    "    old_title = str(graph.value(proc, PRO.title) or \"\")\n",
    "    old_description = str(graph.value(proc, PRO.description) or \"\")\n",
    "    old_processId = str(graph.value(proc, PRO.processId) or \"\")\n",
    "    old_referenceUrls = str(graph.value(proc, PRO.referenceUrls) or \"\")\n",
    "    \n",
    "    new_title = generate_with_llm(llm, config, \"Process\", \"title\", old_title) if old_title else \"Process \" + fake.word().title()\n",
    "    new_description = generate_with_llm(llm, config, \"Process\", \"description\", old_description) if old_description else fake.sentence(nb_words=10)\n",
    "    new_referenceUrls = fake.url()\n",
    "    \n",
    "    graph.set((proc, PRO.title, Literal(new_title)))\n",
    "    graph.set((proc, PRO.description, Literal(new_description)))\n",
    "    graph.set((proc, PRO.processId, Literal(new_processId)))\n",
    "    graph.set((proc, PRO.referenceUrls, Literal(new_referenceUrls)))\n",
    "    \n",
    "    mapping_record.update({\n",
    "        \"title\": {\"old\": old_title, \"new\": new_title},\n",
    "        \"description\": {\"old\": old_description, \"new\": new_description},\n",
    "        \"processId\": {\"old\": old_processId, \"new\": new_processId},\n",
    "        \"referenceUrls\": {\"old\": old_referenceUrls, \"new\": new_referenceUrls}\n",
    "    })\n",
    "    return mapping_record\n",
    "\n",
    "def anonymize_sources(graph):\n",
    "    mapping_records = {}\n",
    "    for s, p, o in graph.triples((None, SCHEMA.sources, None)):\n",
    "        old_source = str(o)\n",
    "        new_source = old_source\n",
    "        new_source = re.sub(r\"https://cosmos\\.siemens-energy\\.cloud\", \"https://example.company.cloud\", new_source)\n",
    "        new_source = re.sub(r\"https://finance-center\\.mosaic\\.siemens-energy\\.cloud\", \"https://example.company.cloud\", new_source)\n",
    "        \n",
    "        if \"employeeGid=\" in new_source:\n",
    "            anonymized_gid = str(graph.value(s, SCHEMA.gid) or \"\")\n",
    "            if anonymized_gid:\n",
    "                new_source = re.sub(r\"(employeeGid=)[^&]+\", r\"\\g<1>\" + anonymized_gid, new_source)\n",
    "        if \"id=\" in new_source and (s, RDF.type, SCHEMA.Person) in graph:\n",
    "            anonymized_id = str(graph.value(s, SCHEMA.id) or \"\")\n",
    "            if anonymized_id:\n",
    "                new_source = re.sub(r\"(id=)[^&]+\", r\"\\g<1>\" + anonymized_id, new_source)\n",
    "        if \"process_id=\" in new_source and (s, RDF.type, PRO.Process) in graph:\n",
    "            anonymized_process_id = str(graph.value(s, PRO.processId) or \"\")\n",
    "            if anonymized_process_id:\n",
    "                new_source = re.sub(r\"(process_id=)[^&]+\", r\"\\g<1>\" + anonymized_process_id, new_source)\n",
    "        if \"appId=\" in new_source and (s, RDF.type, APP.Application) in graph:\n",
    "            anonymized_app_id = str(graph.value(s, APP.appId) or \"\")\n",
    "            if anonymized_app_id:\n",
    "                new_source = re.sub(r\"(appId=)[^&]+\", r\"\\g<1>\" + anonymized_app_id, new_source)\n",
    "        \n",
    "        if new_source != old_source:\n",
    "            graph.set((s, SCHEMA.sources, Literal(new_source)))\n",
    "        mapping_records[old_source] = new_source\n",
    "    return mapping_records\n",
    "\n",
    "def anonymize_all_entities(graph, llm, config):\n",
    "    overall_mapping = {}\n",
    "    for person in graph.subjects(RDF.type, SCHEMA.Person):\n",
    "        overall_mapping[str(person)] = {\"type\": \"Person\", \"mapping\": anonymize_person(graph, person, llm, config)}\n",
    "    for org in graph.subjects(RDF.type, SCHEMA.Organization):\n",
    "        overall_mapping[str(org)] = {\"type\": \"Organization\", \"mapping\": anonymize_organization(graph, org, llm, config)}\n",
    "    for app in graph.subjects(RDF.type, APP.Application):\n",
    "        overall_mapping[str(app)] = {\"type\": \"Application\", \"mapping\": anonymize_application(graph, app, llm, config)}\n",
    "    for proc in graph.subjects(RDF.type, PRO.Process):\n",
    "        overall_mapping[str(proc)] = {\"type\": \"Process\", \"mapping\": anonymize_process(graph, proc, llm, config)}\n",
    "    sources_mapping = anonymize_sources(graph)\n",
    "    if sources_mapping:\n",
    "        overall_mapping[\"sources\"] = {\"type\": \"sources\", \"mapping\": sources_mapping}\n",
    "    return overall_mapping\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    input_ttl = r\"kgCreation\\ExtendedFinKG_Pro.ttl\"\n",
    "    output_ttl = r\"anonymize\\ExtendedFinKG_Pro_anonymized_llm_test.ttl\"\n",
    "    mapping_file = r\"anonymize\\anonymization_mapping_llm_test.json\"\n",
    "    \n",
    "    config = load_config()\n",
    "    llm = initialize_azure_client(config)\n",
    "    \n",
    "    try:\n",
    "        test_response = generate_with_llm(llm, config, \"Organization\", \"name\", \"TestCorp\")\n",
    "        print(f\"Test LLM response: {test_response}\")\n",
    "    except Exception as e:\n",
    "        print(f\"LLM test failed: {e}\")\n",
    "        raise\n",
    "    \n",
    "    print(\"Loading RDF data...\")\n",
    "    g = Graph()\n",
    "    g.parse(input_ttl, format=\"turtle\")\n",
    "    \n",
    "    print(\"Anonymizing RDF entities with LLM...\")\n",
    "    overall_mapping = anonymize_all_entities(g, llm, config)\n",
    "    \n",
    "    g.serialize(destination=output_ttl, format=\"turtle\")\n",
    "    print(f\"Updated RDF graph saved to {output_ttl}\")\n",
    "    \n",
    "    with open(mapping_file, \"w\") as f:\n",
    "        json.dump(overall_mapping, f, indent=2)\n",
    "    print(f\"Overall mapping saved to {mapping_file}\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "def load_mapping(json_file):\n",
    "    \"\"\"Load the overall JSON mapping produced from the RDF anonymization.\"\"\"\n",
    "    with open(json_file, \"r\") as f:\n",
    "        mapping = json.load(f)\n",
    "    return mapping\n",
    "\n",
    "def flatten_mapping(overall_mapping, min_length=3):\n",
    "    \"\"\"\n",
    "    Convert the nested overall mapping into a flat dictionary that maps\n",
    "    each original sensitive string to its new anonymized value.\n",
    "    For Person entities, combine givenName and familyName into a full name.\n",
    "    \"\"\"\n",
    "    flat = {}\n",
    "    for entity, record in overall_mapping.items():\n",
    "        entity_type = record.get(\"type\")\n",
    "        mapping = record.get(\"mapping\", {})\n",
    "        if entity_type == \"Person\":\n",
    "            # Combine givenName and familyName into full name\n",
    "            old_given = mapping.get(\"givenName\", {}).get(\"old\", \"\")\n",
    "            old_family = mapping.get(\"familyName\", {}).get(\"old\", \"\")\n",
    "            new_given = mapping.get(\"givenName\", {}).get(\"new\", \"\")\n",
    "            new_family = mapping.get(\"familyName\", {}).get(\"new\", \"\")\n",
    "            old_full_name = f\"{old_given} {old_family}\".strip()\n",
    "            new_full_name = f\"{new_given} {new_family}\".strip()\n",
    "            if len(old_full_name) >= min_length and old_full_name and new_full_name:\n",
    "                flat[old_full_name] = new_full_name\n",
    "            # Include other fields like gid, email, etc.\n",
    "            for field, vals in mapping.items():\n",
    "                if field not in [\"givenName\", \"familyName\"]: \n",
    "                    orig = str(vals.get(\"old\", \"\"))\n",
    "                    new_val = str(vals.get(\"new\", \"\"))\n",
    "                    if len(orig) >= min_length and orig and new_val:\n",
    "                        flat[orig] = new_val\n",
    "        else:\n",
    "            # Handle other entity types (Organization, Application, Process, sources)\n",
    "            for key, vals in mapping.items():\n",
    "                if isinstance(vals, dict) and \"old\" in vals and \"new\" in vals:\n",
    "                    orig = str(vals[\"old\"])\n",
    "                    new_val = str(vals[\"new\"])\n",
    "                else:  # For \"sources\" mapping\n",
    "                    orig = str(key)\n",
    "                    new_val = str(vals)\n",
    "                if len(orig) >= min_length and orig and new_val:\n",
    "                    flat[orig] = new_val\n",
    "    return flat\n",
    "\n",
    "def anonymize_text(text, flat_mapping, use_word_boundaries=False):\n",
    "    \"\"\"\n",
    "    Replace each occurrence of any original sensitive string (a key in flat_mapping)\n",
    "    with its new value. Prioritize longer strings (like full names) first.\n",
    "    \"\"\"\n",
    "    if not isinstance(text, str):\n",
    "        return text  \n",
    "    for original in sorted(flat_mapping.keys(), key=len, reverse=True):\n",
    "        new_val = flat_mapping[original]\n",
    "        if use_word_boundaries:\n",
    "            pattern = r'\\b' + re.escape(original) + r'\\b'\n",
    "        else:\n",
    "            pattern = re.escape(original)\n",
    "        text = re.sub(pattern, new_val, text)\n",
    "    return text\n",
    "\n",
    "def process_excel_file(input_excel, output_excel, flat_mapping, columns_to_process=[\"Query\", \"Ground Truth Answer\"], use_word_boundaries=False):\n",
    "    \"\"\"\n",
    "    Load an Excel file, replace sensitive text in the specified columns using the flat mapping.\n",
    "    \"\"\"\n",
    "    # Load Excel file\n",
    "    df = pd.read_excel(input_excel)\n",
    "    # Process each specified column\n",
    "    for col in columns_to_process:\n",
    "        if col in df.columns:\n",
    "            df[col] = df[col].apply(lambda x: anonymize_text(x, flat_mapping, use_word_boundaries))\n",
    "        else:\n",
    "            print(f\"Warning: Column '{col}' not found in Excel file.\")\n",
    "    # Save the updated Excel file\n",
    "    df.to_excel(output_excel, index=False)\n",
    "    print(f\"Anonymized Excel file saved to: {output_excel}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    mapping_file = r\"anonymize\\anonymization_mapping_llm_test.json\"\n",
    "    input_excel = r\"data\\LLMEval_1.xlsx\"\n",
    "    output_excel = r\"data\\LLMEval_anonymized_llm.xlsx\"\n",
    "\n",
    "    # Load and flatten the mapping\n",
    "    overall_mapping = load_mapping(mapping_file)\n",
    "    flat_mapping = flatten_mapping(overall_mapping, min_length=3)\n",
    "\n",
    "    # Process the Excel file\n",
    "    process_excel_file(\n",
    "        input_excel=input_excel,\n",
    "        output_excel=output_excel,\n",
    "        flat_mapping=flat_mapping,\n",
    "        columns_to_process=[\"Query\", \"Ground Truth Answer\"],\n",
    "        use_word_boundaries=True \n",
    "    )\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
