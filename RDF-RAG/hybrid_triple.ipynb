{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip uninstall numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "import time\n",
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "from types import SimpleNamespace\n",
    "\n",
    "from azure.identity import DefaultAzureCredential\n",
    "from azure.keyvault.secrets import SecretClient\n",
    "from openai import AzureOpenAI\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from transformers import (\n",
    "    DPRContextEncoder, DPRContextEncoderTokenizer,\n",
    "    DPRQuestionEncoder, DPRQuestionEncoderTokenizer\n",
    ")\n",
    "\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"] = \"TRUE\"\n",
    "\n",
    "# --- Global Query Cache ---\n",
    "query_cache = {}\n",
    "\n",
    "# ===== Configuration & Azure Client Setup =====\n",
    "\n",
    "def load_config():\n",
    "    config_path = r\"config.json\" \n",
    "    with open(config_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        config = json.load(f, object_hook=lambda d: SimpleNamespace(**d))\n",
    "    return config\n",
    "\n",
    "def initialize_azure_client(config):\n",
    "    client = SecretClient(vault_url=config.key_vault_url, credential=DefaultAzureCredential())\n",
    "    secret = client.get_secret(config.dev_secret_name)\n",
    "    return AzureOpenAI(api_key=secret.value,\n",
    "                    api_version=config.chat.api_version,\n",
    "                    azure_endpoint=config.chat.azure_endpoint)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ===== Triple Loading & Preprocessing =====\n",
    "\n",
    "def load_triple_text(file_path: str) -> str:\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        return f.read()\n",
    "\n",
    "triple_file_path = r\"kgCreation/FinKGTripleLatestPro.txt\"\n",
    "triple_text = load_triple_text(triple_file_path)\n",
    "\n",
    "def prepare_triple_documents(triple_text: str):\n",
    "    \"\"\"\n",
    "    Split the input text into triple documents.\n",
    "    Each line (non-empty) is assumed to be a triple.\n",
    "    \"\"\"\n",
    "    triple_docs = []\n",
    "    for line in triple_text.splitlines():\n",
    "        line = line.strip()\n",
    "        if not line:\n",
    "            continue\n",
    "        parts = line.split()\n",
    "        if len(parts) < 3:\n",
    "            continue\n",
    "        triple_docs.append({\n",
    "            \"subject\": parts[0],\n",
    "            \"predicate\": parts[1],\n",
    "            \"object\": \" \".join(parts[2:]),\n",
    "            \"text\": line\n",
    "        })\n",
    "    return triple_docs\n",
    "\n",
    "triple_docs = prepare_triple_documents(triple_text)\n",
    "print(f\"Loaded {len(triple_docs)} triples.\")\n",
    "\n",
    "def build_entity_index(triple_docs):\n",
    "    \"\"\"Map each token (from subject and object) to a list of triple texts.\"\"\"\n",
    "    entity_index = defaultdict(list)\n",
    "    for triple in triple_docs:\n",
    "        for token in [triple[\"subject\"], triple[\"object\"]]:\n",
    "            entity_index[token].append(triple[\"text\"])\n",
    "    return dict(entity_index)\n",
    "\n",
    "def build_subject_index(triple_docs):\n",
    "    \"\"\"Map each subject to all triple texts where it appears.\"\"\"\n",
    "    subject_index = defaultdict(list)\n",
    "    for triple in triple_docs:\n",
    "        subject_index[triple[\"subject\"]].append(triple[\"text\"])\n",
    "    return dict(subject_index)\n",
    "\n",
    "def build_object_to_subject_index(triple_docs):\n",
    "    \"\"\"Map each object to a list of subjects.\"\"\"\n",
    "    obj_to_subj = defaultdict(set)\n",
    "    for triple in triple_docs:\n",
    "        obj_to_subj[triple[\"object\"]].add(triple[\"subject\"])\n",
    "    return {k: list(v) for k, v in obj_to_subj.items()}\n",
    "\n",
    "def build_triple_text_mapping(triple_docs):\n",
    "    \"\"\"\n",
    "    Build a corpus (list of triple texts) and mappings:\n",
    "      - text_to_doc: triple text -> triple document.\n",
    "      - text_to_index: triple text -> index in the corpus.\n",
    "    \"\"\"\n",
    "    corpus = []\n",
    "    text_to_doc = {}\n",
    "    text_to_index = {}\n",
    "    for idx, triple in enumerate(triple_docs):\n",
    "        text = triple[\"text\"]\n",
    "        corpus.append(text)\n",
    "        text_to_doc[text] = triple\n",
    "        text_to_index[text] = idx\n",
    "    return corpus, text_to_doc, text_to_index\n",
    "\n",
    "corpus, text_to_doc, text_to_index = build_triple_text_mapping(triple_docs)\n",
    "entity_index = build_entity_index(triple_docs)\n",
    "subject_index = build_subject_index(triple_docs)\n",
    "object_to_subject = build_object_to_subject_index(triple_docs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
      "The class this function is called from is 'DPRContextEncoderTokenizer'.\n",
      "Some weights of the model checkpoint at facebook/dpr-ctx_encoder-single-nq-base were not used when initializing DPRContextEncoder: ['ctx_encoder.bert_model.pooler.dense.bias', 'ctx_encoder.bert_model.pooler.dense.weight']\n",
      "- This IS expected if you are initializing DPRContextEncoder from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DPRContextEncoder from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def tokenize_text(text: str):\n",
    "    return re.findall(r'\\w+', text)\n",
    "\n",
    "# Precompute TF–IDF Vectorizer & DPR Dense Embeddings \n",
    "\n",
    "# Fit a TF–IDF vectorizer on the full corpus.\n",
    "tfidf_vectorizer = TfidfVectorizer(tokenizer=tokenize_text)\n",
    "tfidf_vectorizer.fit(corpus)\n",
    "\n",
    "# Initialize DPR Context Encoder and its tokenizer.\n",
    "dpr_context_tokenizer = DPRContextEncoderTokenizer.from_pretrained(\"facebook/dpr-ctx_encoder-single-nq-base\")\n",
    "dpr_context_model = DPRContextEncoder.from_pretrained(\"facebook/dpr-ctx_encoder-single-nq-base\")\n",
    "\n",
    "def precompute_dense_embeddings(corpus, batch_size=16):\n",
    "    \"\"\"Compute DPR dense embeddings in batches to avoid memory issues.\"\"\"\n",
    "    all_embeddings = []\n",
    "    for i in range(0, len(corpus), batch_size):\n",
    "        batch_texts = corpus[i:i+batch_size]\n",
    "        inputs = dpr_context_tokenizer(batch_texts, return_tensors=\"pt\", truncation=True, padding=True, max_length=512)\n",
    "        with torch.no_grad():\n",
    "            outputs = dpr_context_model(**inputs)\n",
    "            all_embeddings.append(outputs.pooler_output)\n",
    "    return torch.cat(all_embeddings, dim=0)\n",
    "\n",
    "dense_embeddings = precompute_dense_embeddings(corpus, batch_size=16)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ===== Ranking Functions =====\n",
    "\n",
    "def tfidf_rank_documents(query: str, candidate_texts, vectorizer):\n",
    "    \"\"\"\n",
    "    Rank candidate documents using TF–IDF cosine similarity.\n",
    "    \"\"\"\n",
    "    query_vec = vectorizer.transform([query])\n",
    "    candidate_vecs = vectorizer.transform(candidate_texts)\n",
    "    sims = cosine_similarity(query_vec, candidate_vecs)[0]\n",
    "    ranked = sorted(zip(candidate_texts, sims), key=lambda x: x[1], reverse=True)\n",
    "    return ranked\n",
    "\n",
    "def dpr_rank_documents(query: str, candidate_texts, dpr_q_tokenizer, dpr_q_model, dense_embeddings, text_to_index):\n",
    "    \"\"\"\n",
    "    Rank candidate documents using DPR question encoder and cosine similarity.\n",
    "    \"\"\"\n",
    "    inputs = dpr_q_tokenizer(query, return_tensors=\"pt\", truncation=True, padding=True, max_length=512)\n",
    "    with torch.no_grad():\n",
    "        query_emb = dpr_q_model(**inputs).pooler_output \n",
    "    results = []\n",
    "    for text in candidate_texts:\n",
    "        idx = text_to_index[text]\n",
    "        doc_emb = dense_embeddings[idx].unsqueeze(0)  \n",
    "        score = float(torch.nn.functional.cosine_similarity(query_emb, doc_emb)[0])\n",
    "        results.append((text, score))\n",
    "    results.sort(key=lambda x: x[1], reverse=True)\n",
    "    return results\n",
    "\n",
    "def rrf_fusion(ranked1, ranked2, k=60):\n",
    "    \"\"\"\n",
    "    Fuse two ranked lists using Reciprocal Rank Fusion.\n",
    "    \"\"\"\n",
    "    scores = defaultdict(float)\n",
    "    for rank, (doc, _) in enumerate(ranked1):\n",
    "        scores[doc] += 1.0 / (k + rank + 1)\n",
    "    for rank, (doc, _) in enumerate(ranked2):\n",
    "        scores[doc] += 1.0 / (k + rank + 1)\n",
    "    fused = sorted(scores.items(), key=lambda x: x[1], reverse=True)\n",
    "    return fused\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ===== Query Parsing & Retrieval Functions =====\n",
    "\n",
    "def parse_query_with_llm(query: str):\n",
    "    \"\"\"\n",
    "    Use Azure OpenAI to parse the query into a JSON structure with keys \"entities\", \"relationships\", and \"goal\".\n",
    "    \"\"\"\n",
    "    config = load_config()\n",
    "    llm = initialize_azure_client(config)\n",
    "    prompt = [\n",
    "        {\n",
    "                        \"role\": \"system\",\n",
    "            \"content\": f\"\"\"\n",
    "            You are given a natural language query related to employee and organization data. Extract the following details from the query:\n",
    "            - Entities mentioned in the query (e.g., Person name, Organization ID )\n",
    "            - Relationships or attributes being asked for (e.g., line manager, contact info, worksFor)\n",
    "            - Map these relationships or attributes to the correct schema predicates as defined below:\n",
    "            - Person type: Person\n",
    "            - Organization type: Organization\n",
    "            - Application type: Application\n",
    "            - Process Type: Process\n",
    "            - Works For: worksFor\n",
    "            - Email address: email\n",
    "            - last Name: familyName\n",
    "            - First Name: givenName\n",
    "            - Organisation name : name\n",
    "            - Employee status: status\n",
    "            - Description of the organisation : description\n",
    "            - Location: location\n",
    "            - Identifier (GID): gid\n",
    "            - Job Title: jobTitle\n",
    "            - Functional Manager: functionalManager\n",
    "            - Manager: hasManager\n",
    "            - Manges/reporting to: manages\n",
    "            - Contact Info: telephone\n",
    "            - User Type: userType\n",
    "            - Parent Organization: parentOrganization\n",
    "            - Has Head: hasHead\n",
    "            - Has Child Organization: hasChildOrganization\n",
    "            - Organisation has Process: hasProcess\n",
    "            - Title of the application: appName\n",
    "            - Description of the application : appDescription\n",
    "            - Application access link : accessLink \n",
    "            - Application link : appLink\n",
    "            - Application image: appImage\n",
    "            - Application belong to the organisation : partOfOrg\n",
    "            - Application managed by: managedBy\n",
    "            - people managing application : manages\n",
    "            - Application Owner: hasOwner\n",
    "            - Application part of Process: partOfProcess\n",
    "            - Process title: title\n",
    "            - Process description: description\n",
    "            - Process description: description\n",
    "            - Process has application: hasApplication\n",
    "            - Process has owner: hasOwner\n",
    "            - Process has manager: managedBy\n",
    "            - Process has child process: hasChildProcess\n",
    "            - Employee manages process: manages\n",
    "            - Process has a parent process: prentProcess\n",
    "            - Process part of an organisation: partOfOrg\n",
    "            - Process Id : processId\n",
    "            - Process reference Urls: referenceUrls\n",
    "            - Process template urls: templateUrls\n",
    "            - The goal of the query\n",
    "\n",
    "            Provide the response in a JSON format with keys: \"entities\", \"relationships\", \"goal\".\n",
    "            Do not include additional formatting other than JSON.\n",
    "            Sample Output:\n",
    "            {{\n",
    "            \"entities\": {{\n",
    "                \"Dominik Schlueter\": \"Person\",\n",
    "                \"Anubhuti Singh\": \"Person\"\n",
    "            }},\n",
    "            \"relationships\": {{\n",
    "                \"telephone\": \"phone number\",\n",
    "                \"gid\": \"gid\",\n",
    "                \"email\": \"email\"\n",
    "            }},\n",
    "            \"goal\": \"To retrieve the phone number, GID, and email address of Dominik Schlueter and Anubhuti Singh.\"\n",
    "            }}\n",
    "            Query: \"{query}\"\n",
    "            \"\"\"\n",
    "        }\n",
    "    ]\n",
    "    response = llm.chat.completions.create(model=config.chat.model, messages=prompt)\n",
    "    response_content = response.choices[0].message.content.strip()\n",
    "    parsed_data = json.loads(response_content)\n",
    "    if isinstance(parsed_data.get(\"entities\", {}), dict):\n",
    "        parsed_data[\"entities\"] = [{\"name\": k, \"type\": v} for k, v in parsed_data[\"entities\"].items()]\n",
    "    if isinstance(parsed_data.get(\"relationships\", {}), dict):\n",
    "        parsed_data[\"relationships\"] = [{\"relation\": k, \"value\": v} for k, v in parsed_data[\"relationships\"].items()]\n",
    "    return parsed_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def retrieve_relevant_triples_v2(parsed_query, triple_docs, subject_index, object_to_subject,\n",
    "                                 text_to_doc, text_to_index, tfidf_vectorizer, dense_embeddings,\n",
    "                                 dpr_question_tokenizer, dpr_question_model):\n",
    "    \"\"\"\n",
    "    Enhanced retrieval for triples using TF–IDF and DPR with RRF.\n",
    "    Steps:\n",
    "      1. Collect candidate triples where a query entity appears in the object.\n",
    "      2. Rank these candidates using TF–IDF and DPR.\n",
    "      3. Use the top candidate’s subject as the primary id.\n",
    "      4. Retrieve all triples where this primary id appears.\n",
    "      5. Filter those whose predicate matches a query relationship.\n",
    "      6. Expand candidates if a candidate’s object is a URI.\n",
    "      7. Fuse the rankings and return the top‑k triple texts.\n",
    "    \"\"\"\n",
    "    # Extract entities and relationships from parsed_query.\n",
    "    entities = parsed_query.get(\"entities\", [])\n",
    "    relationships = parsed_query.get(\"relationships\", [])\n",
    "    query_entities = []\n",
    "    for ent in entities:\n",
    "        if isinstance(ent, dict):\n",
    "            if ent.get(\"name\") in ['person', 'organization', 'application', 'process']:\n",
    "                query_entities.append(ent[\"type\"])\n",
    "            else:\n",
    "                query_entities.append(ent[\"name\"])\n",
    "        elif isinstance(ent, str):\n",
    "            query_entities.append(ent)\n",
    "    # Extract relationship names\n",
    "    query_relationships = []\n",
    "    for rel in relationships:\n",
    "        if isinstance(rel, dict):\n",
    "            if rel.get(\"relation\"):\n",
    "                query_relationships.append(rel['relation'])\n",
    "            if rel.get(\"value\"):\n",
    "                query_relationships.append(rel['value'])\n",
    "        else:\n",
    "            query_relationships.append(str(rel))\n",
    "\n",
    "    # Candidate selection: select triples where any query entity appears in the object.\n",
    "    candidate_obj = [t for t in triple_docs if any(ent in t[\"object\"] for ent in query_entities)]\n",
    "    if not candidate_obj:\n",
    "        candidate_obj = triple_docs[:]  # fallback: all triples\n",
    "    candidate_obj_texts = [t[\"text\"] for t in candidate_obj]\n",
    "    \n",
    "    # Rank candidates using TF–IDF and DPR (using query entities as the query).\n",
    "    query_str_entities = \" \".join(query_entities)\n",
    "    tfidf_ranked = tfidf_rank_documents(query_str_entities, candidate_obj_texts, tfidf_vectorizer)\n",
    "    dpr_ranked = dpr_rank_documents(query_str_entities, candidate_obj_texts, dpr_question_tokenizer, dpr_question_model, dense_embeddings, text_to_index)\n",
    "    fused_ranking = rrf_fusion(tfidf_ranked, dpr_ranked, k=60)\n",
    "    \n",
    "    primary_id = None\n",
    "    if fused_ranking:\n",
    "        top_text = fused_ranking[0][0]\n",
    "        top_candidate = text_to_doc.get(top_text)\n",
    "        if top_candidate:\n",
    "            primary_id = top_candidate[\"subject\"]\n",
    "    \n",
    "    if primary_id:\n",
    "        primary_candidates = [t for t in triple_docs if t[\"subject\"] == primary_id or t[\"object\"] == primary_id]\n",
    "    else:\n",
    "        primary_candidates = []\n",
    "    \n",
    "\n",
    "    # Additional expand: if an object's value is a URI, include triples where it appears as a subject.\n",
    "    additional_candidates = []\n",
    "    for t in primary_candidates:\n",
    "        if any(rel.lower() in t[\"predicate\"].lower() for rel in query_relationships):\n",
    "            if t[\"object\"].startswith(\"http\"):\n",
    "                if t[\"object\"] in subject_index:\n",
    "                    for txt in subject_index[t[\"object\"]]:\n",
    "                        if txt in text_to_doc:\n",
    "                            additional_candidates.append(text_to_doc[txt])\n",
    "    \n",
    "    combined = {}\n",
    "    for t in primary_candidates + additional_candidates:\n",
    "        combined[t[\"text\"]] = t\n",
    "    combined_candidates = list(combined.values())\n",
    "    if not combined_candidates:\n",
    "        combined_candidates = primary_candidates\n",
    "    candidate_texts_final = [t[\"text\"] for t in combined_candidates]\n",
    "    \n",
    "    # Final re-ranking using query relationships.\n",
    "    final_query_str = \" \".join(query_relationships)\n",
    "    tfidf_ranked_final = tfidf_rank_documents(final_query_str, candidate_texts_final, tfidf_vectorizer)\n",
    "    dpr_ranked_final = dpr_rank_documents(final_query_str, candidate_texts_final, dpr_question_tokenizer, dpr_question_model, dense_embeddings, text_to_index)\n",
    "    final_fused = rrf_fusion(tfidf_ranked_final, dpr_ranked_final, k=60)\n",
    "    return final_fused\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def generate_answer_with_llm(query: str, top_documents):\n",
    "    \"\"\"\n",
    "    Use Azure OpenAI to generate a final answer from the top retrieved triple texts.\n",
    "    \"\"\"\n",
    "    config = load_config()\n",
    "    llm = initialize_azure_client(config)\n",
    "    context = \"\\n\\n\".join(top_documents)\n",
    "    prompt = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": f\"\"\"\n",
    "            You are an AI assistant tasked with answering a query based on the provided context about employees and organizations.\n",
    "            Please provide a detailed and well-structured answer to the user's question.\n",
    " \n",
    "            - Organize the answer into bullet points if appropriate.\n",
    "            - Use headings where relevant.\n",
    "            - Include all relevant details concisely.\n",
    " \n",
    "            Context:\n",
    "            {context}\n",
    " \n",
    "            Question: \"{query}\"\n",
    " \n",
    "            Provide a well-structured answer.\n",
    "            \"\"\"\n",
    "        }\n",
    "    ]\n",
    "    response = llm.chat.completions.create(model=config.chat.model, messages=prompt)\n",
    "    return response.choices[0].message.content.strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ===== Excel Processing =====\n",
    "\n",
    "def process_queries_excel(input_excel: str, output_excel: str, k_list=[1,2,3,5,8,13,15,21]):\n",
    "    df = pd.read_excel(input_excel)\n",
    "    # Create output columns for each desired top-k value.\n",
    "    for k_val in k_list:\n",
    "        df[f'Top-{k_val} Triples'] = ''\n",
    "        df[f'Parsed Query'] = ''\n",
    "        df[f'Top-{k_val} Answer'] = ''\n",
    "        df[f\"Top-{k_val} Retrieval Time(s)\"] = ''\n",
    "        df[f\"Top-{k_val} Response Time(s)\"] = ''\n",
    "    \n",
    "    # Initialize DPR question encoder and tokenizer.\n",
    "    dpr_question_tokenizer = DPRQuestionEncoderTokenizer.from_pretrained(\"facebook/dpr-question_encoder-single-nq-base\")\n",
    "    dpr_question_model = DPRQuestionEncoder.from_pretrained(\"facebook/dpr-question_encoder-single-nq-base\")\n",
    "    \n",
    "    for index, row in df.iterrows():\n",
    "        query = row[\"Query\"]\n",
    "        try:\n",
    "            start_time = time.time()\n",
    "            parsed_query = parse_query_with_llm(query)\n",
    "            top_k = retrieve_relevant_triples_v2(parsed_query, triple_docs, subject_index,\n",
    "                                                object_to_subject, text_to_doc, text_to_index,\n",
    "                                                tfidf_vectorizer, dense_embeddings,\n",
    "                                                dpr_question_tokenizer, dpr_question_model)\n",
    "            retrieval_time = time.time() - start_time\n",
    "            df.at[index, 'Parsed Query'] = json.dumps(parsed_query)\n",
    "            for k_val in k_list:\n",
    "                top_k_triples = [t[0] for t in top_k[:k_val]]\n",
    "                start_resp = time.time()\n",
    "                answer = generate_answer_with_llm(query, top_k_triples)\n",
    "                response_time = time.time() - start_resp\n",
    "                df.at[index, f\"Top-{k_val} Answer\"] = answer\n",
    "                df.at[index, f\"Top-{k_val} Triples\"] = \"\\n\\n\".join(top_k_triples)\n",
    "                df.at[index, f\"Top-{k_val} Retrieval Time(s)\"] = retrieval_time\n",
    "                df.at[index, f\"Top-{k_val} Response Time(s)\"] = response_time\n",
    "        except Exception as e:\n",
    "            df.at[index, 'Parsed Query'] = f\"Error: {e}\"\n",
    "            for k_val in k_list:\n",
    "                df.at[index, f\"Top-{k_val} Triples\"] = f\"Error: {e}\"\n",
    "                df.at[index, f\"Top-{k_val} Answer\"] = f\"Error: {e}\"\n",
    "                df.at[index, f\"Top-{k_val} Retrieval Time(s)\"] = None\n",
    "                df.at[index, f\"Top-{k_val} Response Time(s)\"] = None\n",
    "\n",
    "    df.to_excel(output_excel, index=False)\n",
    "    print(f\"Processed {len(df)} queries. Output saved to {output_excel}\")\n",
    "\n",
    "# ===== Main Execution =====\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    input_excel_path = r\"data/LLMEval_1.xlsx\"\n",
    "    output_excel_path = r\"Outputs/LLM_responses_rag_triples_multiHop.xlsx\"\n",
    "    process_queries_excel(input_excel_path, output_excel_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
